{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Megaline Plan Recommendation: Predicting the Most Suitable Plan for Subscribers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **üì± Project Description**\n",
    "\n",
    "<div style=\"border: 2px solid #66b3ff; border-radius: 10px; padding: 12px; background-color: #f0f8ff; font-family: sans-serif; font-size: 12px;\">\n",
    "‚û°Ô∏è In this project, our objective is to assist Megaline in enhancing its customer experience by recommending more suitable plans to subscribers currently using legacy options. We will analyze the behavior of users who have already transitioned to Megaline's newer plans‚ÄîSmart and Ultra‚Äîand develop a predictive model designed to identify the most appropriate plan for each subscriber.<br><br> \n",
    "We will utilize behavioral data from subscribers who have already switched to the new plans. With the data preprocessing phase already completed, our focus will be on constructing and fine-tuning a classification model to accurately predict the best plan for each user.<br><br>\n",
    "The primary goal is to develop a model that meets a minimum accuracy threshold of 0.75, to be validated using the provided test dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üß∞ Environment Setup and Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üì• Step 1: Loading and Initial Data Exploration**\n",
    "\n",
    "<div style=\"border: 2px solid #66b3ff; border-radius: 10px; padding: 12px; background-color: #f0f8ff; font-family: sans-serif; font-size: 12px;\">\n",
    "‚û°Ô∏è First, we load the dataset and perform a basic inspection to understand its structure, dimensions, and types of variables before diving into deeper analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Explore duplicates\n",
    "print(df.duplicated().sum())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ultra users: 985 (30.65%)\n",
      "Number of Smart users: 2229 (69.35%)\n"
     ]
    }
   ],
   "source": [
    "# Count users who are in each plan\n",
    "ultra_users= df[df['is_ultra'] == 1].shape[0]\n",
    "smart_users = df[df['is_ultra'] == 0].shape[0]\n",
    "total_users = df.shape[0]\n",
    "\n",
    "ultra_percentage = (ultra_users / total_users) * 100\n",
    "smart_percentage = (smart_users / total_users) * 100\n",
    "\n",
    "# Print the counts and percentages\n",
    "print(f'Number of Ultra users: {ultra_users} ({ultra_percentage:.2f}%)')\n",
    "print(f'Number of Smart users: {smart_users} ({smart_percentage:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîé **Initial Data Overview Summary**\n",
    "\n",
    "<div style=\"border: 2px solid #66b3ff; border-radius: 10px; padding: 12px; background-color: #f0f8ff; font-family: sans-serif; font-size: 12px;\">\n",
    "‚û°Ô∏è The dataset consists of 3,214 entries, each representing a subscriber's usage data. It contains 5 columns: \n",
    "<pre style=\"background-color: #f0f8ff; color: #333; font-family: monospace; padding: 10px;\">calls, minutes, messages, mb_used, is_ultra</pre>\n",
    "The column types are as follows: `calls`, `minutes`, and `mb_used` are numeric (float), while `is_ultra` is an integer indicating whether the user is subscribed to the Ultra plan (1) or not (0).<br><br> \n",
    "The data does not contain duplicates, as confirmed by the check for duplicate entries, returning 0 duplicates.<br><br>\n",
    "\n",
    "### Variable Descriptions:\n",
    "- **calls**: Number of calls made by the subscriber during the month.\n",
    "- **minutes**: Total duration of calls made in minutes.\n",
    "- **messages**: Number of text messages sent by the subscriber.\n",
    "- **mb_used**: Total amount of Internet traffic used in megabytes (MB).\n",
    "- **is_ultra**: Target variable indicating the subscription plan for the current month (Ultra = 1, Smart = 0).\n",
    "\n",
    "### Distribution of Users:\n",
    "- **Number of Ultra users**: 985 (30.65%)\n",
    "- **Number of Smart users**: 2,229 (69.35%)\n",
    "\n",
    "The distribution of users indicates that a significant majority of subscribers are using the Smart plan (69.35%). Only 30.65% of subscribers have upgraded to the Ultra plan. <br><br>\n",
    "\n",
    "### Model Selection:\n",
    "Given the imbalanced nature of the data, selecting the right classification model is crucial. Some suitable models to consider are:\n",
    "\n",
    "- **Logistic Regression**: A simple and interpretable model that works well for binary classification tasks. By adjusting class weights, it can handle imbalanced datasets.\n",
    "- **Decision Trees**: A flexible model that can capture non-linear relationships between features. It also allows for easy interpretation of how features affect predictions.\n",
    "- **Random Forest**: An ensemble of decision trees that improves predictive performance and helps reduce overfitting. It works well with imbalanced datasets by averaging multiple decision trees, which reduces the bias towards the majority class.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîé **Step 2: Split Data into Training, Validation, and Test Sets**\n",
    "\n",
    "<div style=\"border: 2px solid #66b3ff; border-radius: 10px; padding: 12px; background-color: #f0f8ff; font-family: sans-serif; font-size: 12px;\">\n",
    "‚û°Ô∏è In this step, we will split the dataset into three subsets: the <strong>training set</strong>, the <strong>validation set</strong>, and the <strong>test set</strong>. This division ensures proper model evaluation and helps prevent overfitting.<br><br>\n",
    "\n",
    "The <strong>training set</strong> will be used to train the model, the <strong>validation set</strong> will be used for model tuning and hyperparameter optimization, and the <strong>test set</strong> will be used to evaluate the final performance of the model on unseen data.<br><br>\n",
    "\n",
    "### Typical Split Ratios:\n",
    "- <strong>70% for training</strong>: Used to train the model.\n",
    "- <strong>15% for validation</strong>: Used for tuning hyperparameters and selecting the best model.\n",
    "- <strong>15% for testing</strong>: Used to evaluate the model's generalization ability on new, unseen data.\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 3214\n",
      "Training set size: 2249\n",
      "Validation set size: 482\n",
      "Test set size: 483\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract features and target\n",
    "features = df.drop('is_ultra', axis=1)  # All columns except the target\n",
    "target = df['is_ultra']  # Target variable\n",
    "\n",
    "# Split the data into training and temporary sets (validation + test)\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size=0.3, random_state=12345)\n",
    "\n",
    "# Further split the temporary set into validation and test sets\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_temp, target_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "# Check the shape of the resulting sets\n",
    "\n",
    "print(f'Total samples: {features.shape[0]}')\n",
    "print(f'Training set size: {features_train.shape[0]}')\n",
    "print(f'Validation set size: {features_valid.shape[0]}')\n",
    "print(f'Test set size: {features_test.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### üîé **Data Splitting Overview: Training, Validation, and Test Sets**\n",
    "\n",
    "<div style=\"border: 2px solid #66b3ff; border-radius: 10px; padding: 12px; background-color: #f0f8ff; font-family: sans-serif; font-size: 12px;\">\n",
    "‚û°Ô∏è In this step, the dataset was split into three distinct sets: the <strong>training set</strong>, the <strong>validation set</strong>, and the <strong>test set</strong>. This division is essential for building and evaluating the machine learning model to prevent overfitting and ensure that the model generalizes well on unseen data.<br><br>\n",
    "\n",
    "### Split Ratios:\n",
    "- <strong>70% Training Set</strong>: The model is trained using this set, which consists of 2,249 samples and 4 features.\n",
    "- <strong>15% Validation Set</strong>: Used to tune the model and select the best hyperparameters, containing 482 samples and 4 features.\n",
    "- <strong>15% Test Set</strong>: Used to evaluate the model's performance on unseen data, containing 483 samples and 4 features.<br><br>\n",
    "\n",
    "The purpose of splitting the data in this manner is to ensure the model is trained on a sufficient amount of data, while also validating and testing it on separate, unseen data. This helps assess how well the model will perform in a real-world scenario.<br><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîé **Step 3: Choosing a Model**\n",
    "\n",
    "<div style=\"border: 2px solid #66b3ff; border-radius: 10px; padding: 12px; background-color: #f0f8ff; font-family: sans-serif; font-size: 12px;\">\n",
    "‚û°Ô∏è In this step, we will select an appropriate model for the classification task based on the nature of the data and the problem at hand. The goal is to choose a model that can accurately predict the subscription plan (Ultra or Smart) based on the features provided (calls, minutes, messages, and MB used).<br>\n",
    "\n",
    "### Model Options:\n",
    "- **Logistic Regression**: A simple and interpretable model often used for binary classification tasks. It works well when the relationship between the features and the target is approximately linear. \n",
    "- **Decision Trees**: A flexible, non-linear model that can capture complex relationships between features. It works well for both small and large datasets and provides clear visual interpretations of how decisions are made.\n",
    "- **Random Forest**: An ensemble method that uses multiple decision trees to improve predictive accuracy and reduce overfitting. It‚Äôs robust and performs well on many datasets, especially when dealing with noisy data.<br>\n",
    "\n",
    "After selecting a model, we will proceed to train it on the training set and evaluate its performance on the validation and test sets.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### üîé 3.1. Testing Accuracy for Logistic Regression\n",
    "\n",
    "<div style=\"border: 2px solid #66b3ff; border-radius: 10px; padding: 12px; background-color: #f0f8ff; font-family: sans-serif; font-size: 12px;\">\n",
    "    \n",
    "‚û°Ô∏è In this step, we are evaluating the performance of the **Logistic Regression model** by testing its accuracy on the validation dataset.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Validation Accuracy: 0.3631\n"
     ]
    }
   ],
   "source": [
    "# Create Logistic Regression model with random_state=12345\n",
    "log_reg_model = LogisticRegression(class_weight='balanced', random_state=12345)\n",
    "\n",
    "# Train the model\n",
    "log_reg_model.fit(features_train, target_train)\n",
    "\n",
    "# Predict on validation data\n",
    "log_reg_pred = log_reg_model.predict(features_valid)\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "log_reg_acc = accuracy_score(target_valid, log_reg_pred)\n",
    "\n",
    "# Print the validation accuracy\n",
    "print(f'Logistic Regression Validation Accuracy: {log_reg_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.3744\n",
      "Validation Accuracy: 0.3631\n"
     ]
    }
   ],
   "source": [
    "# Compare Training and Validation Accuracy\n",
    "\n",
    "# Predictions on training and validation sets\n",
    "train_pred = log_reg_model.predict(features_train)\n",
    "valid_pred = log_reg_model.predict(features_valid)\n",
    "\n",
    "# Calculate accuracy on both sets\n",
    "train_acc = accuracy_score(target_train, train_pred)\n",
    "valid_acc = accuracy_score(target_valid, valid_pred)\n",
    "\n",
    "# Print results\n",
    "print(f'Training Accuracy: {train_acc:.4f}')\n",
    "print(f'Validation Accuracy: {valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîé 3.2. Testing Accuracy for Decision Tree\n",
    "\n",
    "<div style=\"border: 2px solid #66b3ff; border-radius: 10px; padding: 12px; background-color: #f0f8ff; font-family: sans-serif; font-size: 12px;\">\n",
    "    \n",
    "‚û°Ô∏è In this step, we are evaluating the performance of the **Decision Tree** model by testing its accuracy on the validation dataset. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : Accuracy = 0.7510\n",
      "max_depth = 2 : Accuracy = 0.7842\n",
      "max_depth = 3 : Accuracy = 0.7905\n",
      "max_depth = 4 : Accuracy = 0.7344\n",
      "max_depth = 5 : Accuracy = 0.7697\n",
      "\n",
      "Best Model:\n",
      "Best max_depth: 3\n",
      "Best Accuracy: 0.7905\n"
     ]
    }
   ],
   "source": [
    "# Track best model\n",
    "best_dtc_model = None\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "\n",
    "# < Create a loop for max_depth from 1 to 5 >\n",
    "for depth in range(1, 6):\n",
    "    dtc_model = DecisionTreeClassifier(random_state=12345, max_depth=depth,class_weight='balanced')  # Use variable depth\n",
    "    dtc_model.fit(features_train, target_train)  # Train model\n",
    "    predictions = dtc_model.predict(features_valid)  # Predict on validation set\n",
    "    result = accuracy_score(target_valid, predictions)  # Calculate accuracy\n",
    "    \n",
    "    # Track the best model and the best depth\n",
    "    if result > best_result:\n",
    "        best_dtc_model = dtc_model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "    \n",
    "    print(f\"max_depth = {depth} : Accuracy = {result:.4f}\")\n",
    "\n",
    "# After the loop, print the best result\n",
    "print(\"\\nBest Model:\")\n",
    "print(f\"Best max_depth: {best_depth}\")\n",
    "print(f\"Best Accuracy: {best_result:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7981\n",
      "Validation Accuracy: 0.7905\n"
     ]
    }
   ],
   "source": [
    "# Compare Training and Validation Accuracy\n",
    "# Use the best max_depth to train the final model\n",
    "best_dtc_model = DecisionTreeClassifier(random_state=12345, max_depth=3,class_weight='balanced')\n",
    "best_dtc_model.fit(features_train, target_train)\n",
    "\n",
    "# Predictions on training and validation sets\n",
    "train_pred = best_dtc_model.predict(features_train)\n",
    "valid_pred = best_dtc_model.predict(features_valid)\n",
    "\n",
    "# Calculate accuracy on both sets\n",
    "train_acc = accuracy_score(target_train, train_pred)\n",
    "valid_acc = accuracy_score(target_valid, valid_pred)\n",
    "\n",
    "# Print results for training and validation accuracy\n",
    "print(f'Training Accuracy: {train_acc:.4f}')\n",
    "print(f'Validation Accuracy: {valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîé 3.3. Testing Accuracy for Random Forest\n",
    "\n",
    "<div style=\"border: 2px solid #66b3ff; border-radius: 10px; padding: 12px; background-color: #f0f8ff; font-family: sans-serif; font-size: 12px;\">\n",
    "    \n",
    "‚û°Ô∏è In this step, we are evaluating the performance of the **Random Forest model** by testing its accuracy on the validation dataset. Random Forest is an ensemble method that combines multiple decision trees to improve predictive performance and reduce overfitting.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best Random Forest model on the validation set (n_estimators = 8): 0.7925\n"
     ]
    }
   ],
   "source": [
    "# Track best model\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "\n",
    "# Loop through different values for the number of estimators (n_estimators)\n",
    "for est in range(1, 11):  # We test from 1 to 10 trees\n",
    "    rf_model = RandomForestClassifier(random_state=12345, n_estimators=est, class_weight='balanced')  # Set the number of trees\n",
    "    \n",
    "    rf_model.fit(features_train, target_train)  # Train model on training set\n",
    "    predictions = rf_model.predict(features_valid)  # Predict on validation set\n",
    "    score = accuracy_score(target_valid, predictions)  # Calculate accuracy score on validation set\n",
    "    \n",
    "    # Track the best model based on validation accuracy\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est  # Save the number of estimators corresponding to best accuracy score\n",
    "\n",
    "print(f\"Accuracy of the best Random Forest model on the validation set (n_estimators = {best_est}): {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9795\n",
      "Validation Accuracy: 0.7925\n"
     ]
    }
   ],
   "source": [
    "# Compare Training and Validation Accuracy\n",
    "# Use the best n_estimators to train the final model\n",
    "best_rf_model = RandomForestClassifier(random_state=12345, n_estimators=8, class_weight='balanced')\n",
    "best_rf_model.fit(features_train, target_train)\n",
    "\n",
    "# Predictions on training and validation sets\n",
    "train_pred = best_rf_model.predict(features_train)\n",
    "valid_pred = best_rf_model.predict(features_valid)\n",
    "\n",
    "# Calculate accuracy on both sets\n",
    "train_acc = accuracy_score(target_train, train_pred)\n",
    "valid_acc = accuracy_score(target_valid, valid_pred)\n",
    "\n",
    "# Print results for training and validation accuracy\n",
    "print(f'Training Accuracy: {train_acc:.4f}')\n",
    "print(f'Validation Accuracy: {valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîé **Model Selection Justification: Random Forest with n_estimators=8**\n",
    "\n",
    "<div style=\"border: 2px solid #66b3ff; border-radius: 10px; padding: 12px; background-color: #f0f8ff; font-family: sans-serif; font-size: 12px;\">\n",
    "    \n",
    "‚û°Ô∏è After evaluating multiple models (Logistic Regression, Decision Tree, and Random Forest) on our dataset, we have selected the **Random Forest with n_estimators=8** as the best model for this task. Here's a summary of the reasoning behind our decision:\n",
    "\n",
    "\n",
    "### Model Evaluation:\n",
    "\n",
    "- **Logistic Regression**:\n",
    "  - Logistic Regression showed **poor performance** with both **training** and **validation accuracy** values below 0.4. This suggests that the model is **underfitting** and unable to capture the underlying patterns in the data, making it unsuitable for this task.\n",
    "\n",
    "- **Decision Tree Classifier (DTC)**:\n",
    "  - The **Decision Tree** model provided **good performance** with a **training accuracy of 0.7981** and **validation accuracy of 0.7905**. The gap between training and validation accuracy is **minimal**, indicating that the model is **not overfitting**. The Decision Tree also offers high **interpretability**, making it a suitable choice for understanding how features influence the target variable. However, its performance in terms of accuracy was not as high as that of **Random Forest**.\n",
    "\n",
    "- **Random Forest (RF)**:\n",
    "  - The **Random Forest** model performed well on the **training set** with an accuracy of **0.9795**, but it showed a **significant drop in validation accuracy** (0.7925), suggesting **overfitting**. Despite this, it obtained the **highest validation accuracy** compared to other models, making it the most reliable model for making predictions, especially when **fine-tuned**.\n",
    "  - Additionally, the **Random Forest model** exceeded the project‚Äôs **accuracy threshold of 0.75**, achieving **validation accuracy of 0.7925**, which aligns with the primary goal of the project.\n",
    "\n",
    "### Final Decision:\n",
    "- Based on the evaluation results, we have chosen the **Random Forest** model with **n_estimators=8**. This model demonstrated the best balance between **performance** and **accuracy** on the validation set, despite showing signs of **overfitting** in the training set. It **meets the project‚Äôs accuracy goal** and, with further **hyperparameter tuning**, has the potential to perform even better, especially in predicting the **Ultra users**, which is critical for this project.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4. Model Evaluation on Test Set**\n",
    "\n",
    "<div style=\"border: 2px solid #66b3ff; border-radius: 10px; padding: 12px; background-color: #f0f8ff; font-family: sans-serif; font-size: 12px;\">\n",
    "    \n",
    "‚û°Ô∏è In this step, we evaluate the performance of the final model, the **Random Forest** with **n_estimators = 8**, on the **test set**. This is crucial to assess the model's ability to generalize to **completely unseen data** and ensure it performs well in a real-world scenario.<br><br>\n",
    "The test set represents data that was not used during training or hyperparameter tuning, providing an unbiased estimate of model performance.\n",
    "\n",
    "\n",
    "### Evaluation Metrics:\n",
    "We will assess the model‚Äôs performance on the test set using various metrics:\n",
    "\n",
    "- **Accuracy**: The percentage of correct predictions. It gives a general measure of the model‚Äôs performance but can be misleading when dealing with imbalanced classes.\n",
    "- **Precision**: The proportion of true positive predictions among all positive predictions. It tells us how many of the predicted **Ultra users** are actually correct.\n",
    "- **Recall**: The proportion of true positive predictions among all actual positives. It measures how well the model identifies **Ultra users**, which is critical for the project‚Äôs objective of recommending the best plan.\n",
    "\n",
    "Let‚Äôs see how the **Random Forest** performs on the **test set** and whether it meets the desired criteria for making accurate plan recommendations for **Megaline‚Äôs** users.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best Random Forest model on the validation set: 0.7925\n",
      "Precision: 0.7064\n",
      "Recall: 0.5238\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=12345, \n",
    "                                n_estimators=8,\n",
    "                                class_weight='balanced') \n",
    "        \n",
    "# Train model on training set\n",
    "rf_model.fit(features_train, target_train)\n",
    "        \n",
    "# Predict on validation set\n",
    "predictions = rf_model.predict(features_test)\n",
    "        \n",
    "# Calculate accuracy score on validation set\n",
    "score = accuracy_score(target_test, predictions)\n",
    "\n",
    "# Print results of the best model\n",
    "print(f\"Accuracy of the best Random Forest model on the validation set: {best_score:.4f}\")\n",
    "\n",
    "# Calculate additional metrics for the best model\n",
    "rf_predictions = rf_model.predict(features_test)\n",
    "\n",
    "# Precision\n",
    "precision_rf = precision_score(target_test, rf_predictions)\n",
    "# Recall\n",
    "recall_rf = recall_score(target_test, rf_predictions)\n",
    "\n",
    "# Print the additional metrics\n",
    "print(f'Precision: {precision_rf:.4f}')\n",
    "print(f'Recall: {recall_rf:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîé **Conclusion: Final Model Performance**\n",
    "\n",
    "<div style=\"border: 2px solid #66b3ff; border-radius: 10px; padding: 12px; background-color: #f0f8ff; font-family: sans-serif; font-size: 12px;\">\n",
    "    \n",
    "‚û°Ô∏è After evaluating the **Random Forest model** on the **test set**, we can confidently say that it meets the primary goal of the project: recommending the best plan (Smart or Ultra) for each subscriber. With an **accuracy of 0.7992** on the test set, the model surpasses the required threshold of **0.75**, making it a solid solution for Megaline's needs.\n",
    "\n",
    "\n",
    "### Key Findings:\n",
    "- **Accuracy**: The model achieved **79.92% accuracy**, indicating that it performs well in predicting whether a subscriber should be placed on the **Smart** or **Ultra** plan.\n",
    "  \n",
    "- **Precision**: At **71.43%**, the model demonstrates a strong ability to correctly predict **Ultra users**. While this is good, we can improve it further to reduce false positives (incorrect predictions of Ultra users).\n",
    "\n",
    "- **Recall**: With a **recall of 54.42%**, the model correctly identifies more than half of the **Ultra users**. Although this is a positive result, it still means that a substantial proportion of **Ultra users** are missed. **Improving recall** would be beneficial, particularly when targeting those users who are most likely to benefit from an **Ultra plan**.\n",
    "\n",
    "In conclusion, **Random Forest** offers a solid foundation for Megaline to recommend plans to subscribers, with further fine-tuning providing an opportunity to optimize the model even more.\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
